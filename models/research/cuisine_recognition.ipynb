{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "import pandas as pd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b0c1ab1a3b763bc7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### preparing menu items for modeling \n",
   "id": "da3c9f6c8438768"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def clean_items_in_list(l, menu_stop_words = [], lemmatize=True):\n",
    "    # ensures menu item lists are ready for processing: removes stop words, punctuation, digits etc. \n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = list(ENGLISH_STOP_WORDS) + menu_stop_words\n",
    "    if isinstance(l, list):\n",
    "        clean_l = []\n",
    "        for item in l:\n",
    "            if isinstance(item, str):\n",
    "                clean_item = \"\".join([c.lower() for c in item if c.isascii() or c == \" \"])\n",
    "                clean_item = \"\".join([c for c in clean_item if not c.isdigit()])\n",
    "                clean_item = \" \".join([c.split(\".\")[-1] for c in clean_item.split() if c not in stop_words])\n",
    "                clean_item = \"\".join([c.lower() for c in clean_item if c not in string.punctuation])\n",
    "                clean_item = \" \".join([c.strip() for c in clean_item.split()])\n",
    "                if lemmatize:\n",
    "                    clean_item = \" \".join([stemmer.stem(c) for c in clean_item.split()])\n",
    "                if clean_item != \"\" and clean_item != \" \":\n",
    "                    clean_l.append(clean_item)\n",
    "        return clean_l\n",
    "    else:\n",
    "        return l"
   ],
   "id": "8277ba3f64607084"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "full_combo[\"Items Processed\"] = full_combo[\"Items\"].apply(clean_items_in_list)",
   "id": "a67a8fe0f7eb4109"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, menu_rest_data[\"Cuisine - Least Frequent\"], test_size=0.25, random_state=42)",
   "id": "a924bd067e942fa3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_true, y_pred)\n",
    "# precision = precision_score(y_true, y_pred, average='weighted')  \n",
    "# recall = recall_score(y_true, y_pred, average='weighted')\n",
    "# f1 = f1_score(y_true, y_pred, average='weighted')"
   ],
   "id": "a389ee762e80c79a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ],
   "id": "6f75d607406402c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "\"https://www.nytimes.com/interactive/2017/12/12/dining/best-restaurant-nyc-pete-wells.html\"",
   "id": "e1a18da9dcd3ff37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Bag of Words Analysis for Domain-Specific Stop Word Removal ",
   "id": "b0e18eeffd1143a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def make_item_corpus(df, item_column):\n",
    "    item_corpus = []    \n",
    "    for menu in df[item_column]: \n",
    "        if isinstance(menu, list):\n",
    "            for item in menu: \n",
    "                item_corpus.append(item)\n",
    "    corpus_lengths = []\n",
    "    for item in item_corpus:\n",
    "        corpus_lengths.append(len(item.split()))\n",
    "    print(\"average item length: \", np.mean(corpus_lengths))\n",
    "    print(\"median item length: \", np.median(corpus_lengths))\n",
    "    return item_corpus"
   ],
   "id": "e1395c0a6e188047"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "item_corpus = make_item_corpus(full_combo, \"Cuisine\")",
   "id": "a9fbe263a6d08e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bow = []\n",
    "for item in item_corpus:\n",
    "    for word in item.split():\n",
    "        bow.append(word)"
   ],
   "id": "3afe8332a7fe03ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bow_freq = pd.DataFrame(bow).value_counts()\n",
    "bow_freq = bow_freq.reset_index()\n",
    "bow_freq.columns = [\"word\", \"frequency\"]\n",
    "bow_freq[\"length\"] = bow_freq[\"word\"].apply(len)"
   ],
   "id": "350f0f32e7334597"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bow_freq",
   "id": "7d7f1daeb1754036"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "percentiles_to_remove = 0.05\n",
    "bow_freq.nlargest(int(len(bow_freq) * percentiles_to_remove), \"frequency\").sort_values([\"length\"], ascending=True)\n",
    "## discussion: In this context, function words are helpful to determine the cuisine (unless they're in English). Thus, perhaps only single character \"words\" should be removed, if that; the two-letter words may be crucial for as they look like function words (such as \"al\", \"en\"). It is unclear if the single-letter words are typos or useful function words in languages other than English. The longer words also seem relevant - knowing if a place is serving \"quesadilla\", \"cheeseburger\" or \"mediterranean\" is very relevant. \n",
    "## Words that will be removed are: (1) single character words; (2) manually reviewed 1% words that have no relevance to the specific cuisine (e.g. \"special\"). Words that may appear in an n-gram (e.g. \"sauce\") will be seperated to test if they should be removed or not.   "
   ],
   "id": "5a9fe67a105e288e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "percentiles_to_remove = 0.01\n",
    "may_be_relevant = [\"salad\", \"fri\", \"sauc\", \"soup\", \"hot\", \"ice\", \"sandwich\"]\n",
    "manual_list = [\"special\", \"lunch\", \"platter\", \"delux\", \"combo\", \"fresh\", \"tray\", \"breakfast\", \"oz\", \"lb\", \"ml\", \"cl\",\n",
    "               \"style\", \"slice\", \"mix\", \"juice\", \"soda\", \"piec\", \"chop\", \"bottl\", \"dinner\", \"cater\", \"hous\", \"larg\",\n",
    "               \"aa\"]\n",
    "bow_freq.nlargest(int(len(bow_freq) * percentiles_to_remove), \"frequency\")"
   ],
   "id": "7ccbfdc03545ea8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "percentiles_to_remove = 0.4\n",
    "bow_freq.nsmallest(int(len(bow_freq) * percentiles_to_remove), \"frequency\")\n",
    "# discussion: all words that only appear once have no value - since they are essentially outliers. "
   ],
   "id": "125b1df7fc47621c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "infrequent_words_to_remove = list(bow_freq.loc[bow_freq[\"frequency\"] < 3][\"word\"])\n",
    "single_letter_words = list(bow_freq.loc[bow_freq[\"length\"] == 1][\"word\"])\n",
    "words_to_remove = single_letter_words + infrequent_words_to_remove + manual_list + may_be_relevant"
   ],
   "id": "897879374ec84f66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "menu_rest_data[\"Items Processing\"] = menu_rest_data[\"Items Processing\"].apply(\n",
    "    lambda x: clean_items_in_list(x, words_to_remove, lemmatize=False))"
   ],
   "id": "6069bd6763886c4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "menu_rest_data[\"Items Processing - String\"] = menu_rest_data[\"Items Processing\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else x)\n",
    "menu_rest_data[\"Items Processing - String\"] = menu_rest_data[\"Items Processing - String\"].str.replace(\",\", \"\")"
   ],
   "id": "a85ea4b7f22daf40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "menu_rest_data\n",
    "# menu_rest_data[\"Items Processing - String\"] "
   ],
   "id": "59b9c24bc7369fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "be2e7c26f894e37f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
